"""
HOSS Tracking Filter Module
Implements Kalman filter tracking with proper covariance computation
matching original RIPITT/HOSS format.

Cloned from: radar-tools-master/src/radar_tools/cubature.py
             radar-tools-master/src/radar_tools/nlls.py

The original HOSS uses:
- 9-state filter: position (3), velocity (3), acceleration (3) in ECEF
- CWPA (Coordinated White Process Acceleration) dynamics model
- Cubature Kalman Filter with Stroud53Rule (5th order)
- 9x9 covariance matrix stored as lower-triangular (45 elements: LT0-LT44)
- Nonlinear least squares (NLLS) initialization
- Monte Carlo runs with different noise realizations

Reference: Original HOSS tracking/cwpa_filter.py, run_filter.py, track_data.py
           radar-tools cubature.py, nlls.py
"""

import numpy as np
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple, Callable
from scipy.linalg import cholesky, solve_triangular
from scipy.linalg.lapack import dtrtri, dgeqrf, dtpttr, dtrttp
from scipy.optimize import least_squares
from itertools import product as itp
from functools import lru_cache
from math import sqrt

# Constants
EARTH_RADIUS_M = 6371000.0


def latlon_to_ecef(lat_deg: float, lon_deg: float, alt_m: float) -> np.ndarray:
    """Convert geodetic coordinates to ECEF position."""
    lat_rad = np.radians(lat_deg)
    lon_rad = np.radians(lon_deg)
    r = EARTH_RADIUS_M + alt_m
    x = r * np.cos(lat_rad) * np.cos(lon_rad)
    y = r * np.cos(lat_rad) * np.sin(lon_rad)
    z = r * np.sin(lat_rad)
    return np.array([x, y, z])


# =============================================================================
# Cloned from: radar-tools-master/src/radar_tools/cubature.py
# =============================================================================

def _readonly(r: np.ndarray) -> np.ndarray:
    """Make array read-only for caching."""
    r.setflags(write=False)
    return r


def sqrt_transform_qr(a: np.ndarray, transpose: bool = False, positive_diagonal: bool = True) -> np.ndarray:
    """
    Transform n x m (m > n) square root matrix to LT factor by application of QR decomposition.
    The LT factor has a diagonal that is non-negative.

    Cloned from: radar-tools cubature.py:sqrt_transform_qr
    """
    if not transpose:
        a = a.T

    if not a.dtype == np.float64:
        a = a.astype(np.float64)

    qr, tau, work, info = dgeqrf(a)
    if info != 0:
        raise ValueError(f'dgeqrf QR failed with info {info}')

    n = qr.shape[1]
    qr_tp, info = dtrttp(qr[:n, :], uplo='U')
    if info != 0:
        raise ValueError(f'dtrttp failed with info {info}')

    r, info = dtpttr(n, qr_tp)
    if info != 0:
        raise ValueError(f'dtpttr failed with info {info}')

    if positive_diagonal:
        return r.T * np.sign(np.diag(r))[None, :]
    else:
        return r.T


def solve_K_from_sqrt(Szz: np.ndarray, Pxy: np.ndarray) -> np.ndarray:
    """
    Solve for Kalman gain from innovation square root and cross-covariance.

    Cloned from: radar-tools cubature.py:solve_K_from_sqrt
    """
    Szzi, info = dtrtri(Szz, lower=1)
    if info != 0:
        raise ValueError(f'Cholesky inverse with dtrtri failed, info={info}')
    return Pxy @ Szzi.T @ Szzi


@lru_cache()
def _Stroud53Rule_weights(d: int) -> np.ndarray:
    """Stroud 5-3 rule weights. Cloned from radar-tools."""
    return _readonly(
        np.array(
            [4 / (d + 2) ** 2] * (2 * d) +
            [(d - 2) ** 2 / (2 ** d * (d + 2) ** 2)] * (2 ** d)
        )
    )


@lru_cache()
def _Stroud53Rule_points_n(d: int) -> np.ndarray:
    """Stroud 5-3 rule points. Cloned from radar-tools."""
    return _readonly(
        np.vstack((
            sqrt((d + 2) / 2) * np.eye(d, d),
            -sqrt((d + 2) / 2) * np.eye(d, d),
            sqrt((d + 2) / (d - 2)) * np.array(list(itp([1., -1.], repeat=d))),
        ))
    )


class Stroud53Rule:
    """
    Implementation of 5th order cubature rule due to Stroud.

    Cloned from: radar-tools cubature.py:Stroud53Rule

    This is formula E_n^{r^2}: 5-3 on p 317 of Stroud.
    For a state dimension d, the number of cubature points generated by
    this rule is 2d + 2^d.

    Reference: Crouse, David. "Basic tracking using nonlinear 3D monostatic
    and bistatic measurements." IEEE Aerospace and Electronic Systems Magazine,
    Vol. 29.8, 2014, 4-53.
    """

    def weights(self, d: int) -> np.ndarray:
        if d <= 2:
            raise ValueError('Rule is invalid for d <= 2')
        return _Stroud53Rule_weights(d)

    def points_n(self, d: int) -> np.ndarray:
        if d <= 2:
            raise ValueError('Rule is invalid for d <= 2')
        return _Stroud53Rule_points_n(d)

    def weights_covariance(self, d: int) -> np.ndarray:
        return self.weights(d)


def cubature_propagate(
        t0: float,
        x0: np.ndarray,
        SP0: np.ndarray,
        t1: float,
        f: Callable[[np.ndarray, float, float], np.ndarray],
        SQ: Optional[np.ndarray] = None,
        rule: Optional[Stroud53Rule] = None,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Perform propagation step of square-root cubature Kalman filtering.

    Cloned from: radar-tools cubature.py:cubature_propagate

    Args:
        t0: Initial time
        x0: Initial state vector, shape (nx,)
        SP0: Cholesky lower triangle of initial state covariance, shape (nx,nx)
        t1: Final time
        f: Non-linear state transition function x1 = f(x0, t0, t1)
        SQ: Cholesky lower triangle of process noise covariance
        rule: Cubature rule (defaults to Stroud53Rule)

    Returns:
        x1p: Mean of prior filter state
        SP1p: Cholesky lower triangle of prior covariance
    """
    if rule is None:
        rule = Stroud53Rule()

    d = x0.shape[0]
    weights = rule.weights(d)
    weights_c = rule.weights_covariance(d)
    points_n = rule.points_n(d)

    # Transform normalized points to state space
    input_points = x0 + (points_n @ SP0.T)

    # Propagate through dynamics
    output_points = f(input_points, t0, t1)

    # Calculate mean
    x1p = np.sum(weights[:, None] * output_points, axis=0)

    # Calculate weighted output array
    Y = (np.sqrt(weights_c[:, None]) * (output_points - x1p)).T

    # QR-based sqrt covariance
    if SQ is not None:
        SP1p = sqrt_transform_qr(np.hstack([Y, SQ]))
    else:
        SP1p = sqrt_transform_qr(Y)

    return x1p, SP1p


def cubature_update(
        x1p: np.ndarray,
        SP1p: np.ndarray,
        z: np.ndarray,
        SR: np.ndarray,
        h: Callable[[np.ndarray], np.ndarray],
        rule: Optional[Stroud53Rule] = None,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    Perform update step of square-root cubature Kalman filtering.

    Cloned from: radar-tools cubature.py:cubature_update

    Args:
        x1p: Prior state vector, shape (nx,)
        SP1p: Cholesky lower triangle of prior covariance, shape (nx,nx)
        z: Measurement, shape (nz,)
        SR: Cholesky lower triangle of measurement noise covariance, shape (nz,nz)
        h: Non-linear observation function z = h(x)
        rule: Cubature rule (defaults to Stroud53Rule)

    Returns:
        x1: Mean of posterior state
        SP1: Cholesky lower triangle of posterior covariance
        dz: Innovation vector
        Szz: Innovation covariance Cholesky lower triangle
    """
    if rule is None:
        rule = Stroud53Rule()

    d = x1p.shape[0]
    weights = rule.weights(d)
    weights_c = rule.weights_covariance(d)
    points_n = rule.points_n(d)

    # Transform normalized points to state space
    input_points = x1p + (points_n @ SP1p.T)

    # Push through observation function
    output_points = h(input_points)

    # Calculate mean
    z_hat = np.sum(weights[:, None] * output_points, axis=0)

    # Calculate weighted arrays
    X1P = (np.sqrt(weights_c[:, None]) * (input_points - x1p)).T
    Z = (np.sqrt(weights_c[:, None]) * (output_points - z_hat)).T

    # Innovation covariance sqrt
    Szz = sqrt_transform_qr(np.hstack([Z, SR]))

    # Cross-covariance
    Pxz = X1P @ Z.T

    # Kalman gain
    K = solve_K_from_sqrt(Szz, Pxz)

    # Update state
    dz = z - z_hat
    x1 = x1p + K @ dz

    # Update posterior sqrt covariance (Joseph form)
    SP1 = sqrt_transform_qr(np.hstack([X1P - K @ Z, K @ SR]))

    return x1, SP1, dz, Szz


# =============================================================================
# Cloned from: radar-tools-master/src/radar_tools/nlls.py
# =============================================================================

def _R2Chol(S):
    """
    Change QR decomposition matrix to lower triangular Cholesky factor.
    Cloned from: radar-tools nlls.py
    """
    return S.T @ np.diag(np.sign(np.diag(S.T)))


def nonlinear_least_squares(
        t_out, x0, t_in, z, R, f, h,
        F=None, H=None,
        *, vectorized=False, cholesky=False,
        **kwargs):
    """
    Perform non-linear least squares estimation of state vector.

    Cloned from: radar-tools nlls.py:nonlinear_least_squares

    Args:
        t_out: Time of the output state to be estimated
        x0: Initial estimate of the output state, shape (nx,)
        t_in: Array of input measurement times, shape (nt,)
        z: Input measurement vectors
        R: Input measurement covariance matrices
        f: State propagation function f(x, dt)
        h: Observation function h(x)
        F: Optional Jacobian for state transition
        H: Optional Jacobian for observation
        vectorized: Whether f and h support vectorized input
        cholesky: Whether R is already Cholesky factored

    Returns:
        x_out: Least squares estimate of state at t_out
        P_out: MSE matrix (or Cholesky factor if cholesky=True)
        ls_sol: scipy least_squares solution object
    """
    # Cholesky decomposition of input covariance
    if not cholesky:
        SR = [np.linalg.cholesky(Ri) for Ri in R]
    else:
        SR = R

    def _f_resid(x):
        # Propagate states back in time
        if vectorized:
            x_t = f(x, t_in - t_out)
        else:
            x_t = np.array([f(x, ti - t_out) for ti in t_in])

        # Convert to predicted measurements
        if callable(h):
            if vectorized:
                z_hat = h(x_t)
            else:
                z_hat = [h(xi) for xi in x_t]
        else:
            z_hat = [hi(xi) for xi, hi in zip(x_t, h)]

        # Compute Cholesky-normalized error
        return np.array([
            solve_triangular(SRi, zi - zhi, lower=True)
            for zi, zhi, SRi in zip(z, z_hat, SR)
        ]).ravel()

    if F is not None and H is not None:
        def _jac(x):
            if vectorized:
                x_t = f(x, t_in - t_out)
            else:
                x_t = np.array([f(x, ti - t_out) for ti in t_in])

            F_t = [F(x, ti - t_out) for ti in t_in]

            if callable(H):
                H_t = [np.array([H(xi)]) for xi in x_t]
            else:
                H_t = [Hi(xi) for xi, Hi in zip(x_t, H)]

            return -1.0 * np.vstack([
                solve_triangular(SRi, Hi @ Fi, lower=True)
                for SRi, Hi, Fi in zip(SR, H_t, F_t)
            ])

        ls_sol = least_squares(_f_resid, x0, jac=_jac, **kwargs)
    else:
        ls_sol = least_squares(_f_resid, x0, **kwargs)

    x_out = ls_sol.x
    SI = _R2Chol(np.linalg.qr(ls_sol.jac, mode='r'))
    SII = np.linalg.inv(SI)

    if cholesky:
        SP = _R2Chol(np.linalg.qr(SII, mode='r'))
        return x_out, SP, ls_sol
    else:
        return x_out, SII.T @ SII, ls_sol


# =============================================================================
# Track State and Data Classes
# =============================================================================

@dataclass
class TrackState:
    """Single track state estimate with covariance."""
    time: float
    state: np.ndarray  # 9-element: [pos_x, pos_y, pos_z, vel_x, vel_y, vel_z, acc_x, acc_y, acc_z]
    covariance: np.ndarray  # 9x9 covariance matrix (stored as sqrt factor)

    @property
    def position(self) -> np.ndarray:
        return self.state[:3]

    @property
    def velocity(self) -> np.ndarray:
        return self.state[3:6]

    @property
    def acceleration(self) -> np.ndarray:
        return self.state[6:9]

    @property
    def sqrt_covariance(self) -> np.ndarray:
        """Return lower Cholesky factor of covariance (sqrt_covariance)."""
        return self.covariance  # Already stored as sqrt

    @property
    def full_covariance(self) -> np.ndarray:
        """Return full covariance matrix."""
        return self.covariance @ self.covariance.T

    @property
    def LT_covariance(self) -> np.ndarray:
        """Return lower-triangular covariance as 45-element array (LT0-LT44)."""
        full_cov = self.full_covariance
        lt_elements = []
        for i in range(9):
            for j in range(i + 1):
                lt_elements.append(full_cov[i, j])
        return np.array(lt_elements)


@dataclass
class TrackData:
    """Collection of track states over time - matches original HOSS TrackData."""
    times: np.ndarray
    x_states: np.ndarray  # Shape: (num_monte, num_times, 9)
    LT_covs: np.ndarray   # Shape: (num_monte, num_times, 9, 9) - sqrt covariance

    @property
    def num_monte(self) -> int:
        return self.x_states.shape[0]

    @property
    def num_time_points(self) -> int:
        return self.times.shape[0]

    @property
    def positions_ecef(self) -> np.ndarray:
        """Shape: (num_monte, num_times, 3)"""
        return self.x_states[..., 0:3]

    @property
    def velocities_ecef(self) -> np.ndarray:
        """Shape: (num_monte, num_times, 3)"""
        return self.x_states[..., 3:6]

    @property
    def accelerations_ecef(self) -> np.ndarray:
        """Shape: (num_monte, num_times, 3)"""
        return self.x_states[..., 6:9]

    def get_LT_flat(self, monte_idx: int = 0) -> np.ndarray:
        """Get lower-triangular covariance as (num_times, 45) array."""
        LT_cov_idx_full = np.column_stack([
            np.arange(81),
            np.repeat(np.arange(9), 9),
            np.tile(np.arange(9), 9)
        ])
        LT_cov_idx = LT_cov_idx_full[LT_cov_idx_full[:, 1] >= LT_cov_idx_full[:, 2]][:, 0]

        # Get full covariance from sqrt factor
        num_times = self.num_time_points
        result = np.zeros((num_times, 45))
        for t_idx in range(num_times):
            sqrt_cov = self.LT_covs[monte_idx, t_idx]
            full_cov = sqrt_cov @ sqrt_cov.T
            cov_flat = full_cov.flatten()
            result[t_idx] = cov_flat[LT_cov_idx]
        return result


@dataclass
class TrackMetrics:
    """Track metrics with errors vs truth - matches original HOSS TrackAnalysisMetrics."""
    track_times: np.ndarray
    pos_errors_m: np.ndarray      # Shape: (num_monte, num_times, 3)
    vel_errors_mps: np.ndarray    # Shape: (num_monte, num_times, 3)
    acc_errors_mps2: np.ndarray   # Shape: (num_monte, num_times, 3)
    LT_covs: np.ndarray           # Shape: (num_monte, num_times, 9, 9)

    @property
    def num_monte(self) -> int:
        return self.pos_errors_m.shape[0]

    @property
    def num_time_points(self) -> int:
        return self.track_times.shape[0]

    def get_LT_flat(self, monte_idx: int = 0) -> np.ndarray:
        """Get lower-triangular covariance as (num_times, 45) array."""
        LT_cov_idx_full = np.column_stack([
            np.arange(81),
            np.repeat(np.arange(9), 9),
            np.tile(np.arange(9), 9)
        ])
        LT_cov_idx = LT_cov_idx_full[LT_cov_idx_full[:, 1] >= LT_cov_idx_full[:, 2]][:, 0]

        num_times = self.num_time_points
        result = np.zeros((num_times, 45))
        for t_idx in range(num_times):
            sqrt_cov = self.LT_covs[monte_idx, t_idx]
            full_cov = sqrt_cov @ sqrt_cov.T
            cov_flat = full_cov.flatten()
            result[t_idx] = cov_flat[LT_cov_idx]
        return result


# =============================================================================
# CWPA Filter - Now using Cubature Kalman Filter (CKF) with Stroud53Rule
# =============================================================================

class CWPAFilter:
    """
    Coordinated White Process Acceleration (CWPA) Cubature Kalman Filter.

    State vector: [x, y, z, vx, vy, vz, ax, ay, az] in ECEF coordinates

    Dynamics model: Constant acceleration with white noise jerk
    x(k+1) = F * x(k) + w(k)

    Now uses Cubature Kalman Filter with Stroud53Rule (cloned from RIPITT)
    instead of Extended Kalman Filter for exact match.
    """

    def __init__(self,
                 process_noise_accel: float = 10.0,  # m/s^2 acceleration noise
                 measurement_noise_angle: float = 5e-5,  # radians (bearing measurement error)
                 initial_pos_std: float = 10000.0,  # m
                 initial_vel_std: float = 1000.0,   # m/s
                 initial_acc_std: float = 100.0,    # m/s^2
                 rng: np.random.Generator = None):
        """
        Initialize CWPA filter.

        Args:
            process_noise_accel: Process noise intensity for acceleration (m/s^2)
            measurement_noise_angle: Angular measurement noise (radians)
            initial_pos_std: Initial position standard deviation (m)
            initial_vel_std: Initial velocity standard deviation (m/s)
            initial_acc_std: Initial acceleration standard deviation (m/s^2)
            rng: Random number generator for Monte Carlo
        """
        self.q_accel = process_noise_accel
        self.r_angle = measurement_noise_angle
        self.initial_pos_std = initial_pos_std
        self.initial_vel_std = initial_vel_std
        self.initial_acc_std = initial_acc_std
        self.rng = rng if rng is not None else np.random.default_rng()

        # CKF rule (cloned from RIPITT)
        self.rule = Stroud53Rule()

        # Current state estimate (stored as sqrt covariance)
        self.state: Optional[np.ndarray] = None
        self.sqrt_covariance: Optional[np.ndarray] = None
        self.current_time: Optional[float] = None

        # History for output
        self.history: List[TrackState] = []

    def reset(self):
        """Reset filter state."""
        self.state = None
        self.sqrt_covariance = None
        self.current_time = None
        self.history = []

    def _state_transition_matrix(self, dt: float) -> np.ndarray:
        """
        Build state transition matrix for CWPA model.
        """
        F = np.eye(9)
        dt2 = 0.5 * dt * dt

        F[0, 3] = dt
        F[1, 4] = dt
        F[2, 5] = dt
        F[0, 6] = dt2
        F[1, 7] = dt2
        F[2, 8] = dt2
        F[3, 6] = dt
        F[4, 7] = dt
        F[5, 8] = dt

        return F

    def _process_noise_sqrt(self, dt: float) -> np.ndarray:
        """
        Build sqrt of process noise covariance matrix.
        Returns Cholesky factor SQ such that Q = SQ @ SQ.T
        """
        Q = np.zeros((9, 9))
        q = self.q_accel ** 2

        dt2 = dt * dt
        dt3 = dt2 * dt
        dt4 = dt3 * dt
        dt5 = dt4 * dt

        # Position-position
        Q[0, 0] = Q[1, 1] = Q[2, 2] = q * dt5 / 20.0
        # Position-velocity
        Q[0, 3] = Q[3, 0] = q * dt4 / 8.0
        Q[1, 4] = Q[4, 1] = q * dt4 / 8.0
        Q[2, 5] = Q[5, 2] = q * dt4 / 8.0
        # Position-acceleration
        Q[0, 6] = Q[6, 0] = q * dt3 / 6.0
        Q[1, 7] = Q[7, 1] = q * dt3 / 6.0
        Q[2, 8] = Q[8, 2] = q * dt3 / 6.0
        # Velocity-velocity
        Q[3, 3] = Q[4, 4] = Q[5, 5] = q * dt3 / 3.0
        # Velocity-acceleration
        Q[3, 6] = Q[6, 3] = q * dt2 / 2.0
        Q[4, 7] = Q[7, 4] = q * dt2 / 2.0
        Q[5, 8] = Q[8, 5] = q * dt2 / 2.0
        # Acceleration-acceleration
        Q[6, 6] = Q[7, 7] = Q[8, 8] = q * dt

        # Return Cholesky factor
        try:
            return np.linalg.cholesky(Q + np.eye(9) * 1e-10)
        except np.linalg.LinAlgError:
            # Fallback - use eigenvalue decomposition
            eigvals, eigvecs = np.linalg.eigh(Q)
            eigvals = np.maximum(eigvals, 1e-10)
            return eigvecs @ np.diag(np.sqrt(eigvals))

    def _dynamics_fn(self, x: np.ndarray, t0: float, t1: float) -> np.ndarray:
        """
        Dynamics function for cubature propagation.
        Vectorized: accepts (N, 9) array, returns (N, 9) array.
        """
        dt = t1 - t0
        F = self._state_transition_matrix(dt)

        if x.ndim == 1:
            return F @ x
        else:
            return (F @ x.T).T

    def _observation_fn(self, x: np.ndarray, sat_pos: np.ndarray) -> np.ndarray:
        """
        Observation function for cubature update.
        Vectorized: accepts (N, 9) array, returns (N, 3) array of bearings.
        """
        if x.ndim == 1:
            pos = x[:3]
            delta = pos - sat_pos
            range_m = np.linalg.norm(delta)
            if range_m < 1e-6:
                return delta
            return delta / range_m
        else:
            pos = x[:, :3]
            delta = pos - sat_pos[None, :]
            range_m = np.linalg.norm(delta, axis=1, keepdims=True)
            range_m = np.maximum(range_m, 1e-6)
            return delta / range_m

    def initialize(self, measurements: List[Dict[str, Any]]):
        """
        Initialize filter from first few measurements using NLLS.

        Cloned from: RIPITT uses nonlinear_least_squares for initialization.

        Args:
            measurements: List of measurement dicts with 'time_sec', 'target_pos_ecef',
                         'satellite_pos_ecef', 'bearing'
        """
        if len(measurements) < 2:
            raise ValueError("Need at least 2 measurements to initialize")

        # Extract measurement data
        times = np.array([m['time_sec'] for m in measurements])
        positions = np.array([m['target_pos_ecef'] for m in measurements])
        bearings = np.array([m['bearing'] for m in measurements])
        sat_positions = np.array([m['satellite_pos_ecef'] for m in measurements])

        # Initial guess from position data
        init_pos = positions[0]
        if len(measurements) >= 2:
            dt = times[-1] - times[0]
            if dt > 0:
                init_vel = (positions[-1] - positions[0]) / dt
            else:
                init_vel = np.zeros(3)
        else:
            init_vel = np.zeros(3)
        init_acc = np.zeros(3)

        x0 = np.concatenate([init_pos, init_vel, init_acc])
        t_out = times[-1]

        # Build measurement covariances
        R_list = [np.eye(3) * self.r_angle**2 for _ in measurements]

        # Propagation function for NLLS
        def f_prop(x, dt):
            F = self._state_transition_matrix(dt)
            return F @ x

        # Observation functions for each measurement
        h_list = [lambda x, sp=sp: self._observation_fn(x, sp) for sp in sat_positions]

        try:
            # Use NLLS initialization (cloned from RIPITT)
            x_out, P_out, _ = nonlinear_least_squares(
                t_out, x0, times, bearings, R_list, f_prop, h_list,
                vectorized=False, cholesky=False,
                method='lm', max_nfev=100
            )
            self.state = x_out

            # Convert P to sqrt form
            try:
                self.sqrt_covariance = np.linalg.cholesky(P_out + np.eye(9) * 1e-10)
            except np.linalg.LinAlgError:
                eigvals, eigvecs = np.linalg.eigh(P_out)
                eigvals = np.maximum(eigvals, 1e-10)
                self.sqrt_covariance = eigvecs @ np.diag(np.sqrt(eigvals))

        except Exception:
            # Fallback to linear initialization
            self.state = x0

            # Initial sqrt covariance
            init_cov = np.diag([
                self.initial_pos_std**2, self.initial_pos_std**2, self.initial_pos_std**2,
                self.initial_vel_std**2, self.initial_vel_std**2, self.initial_vel_std**2,
                self.initial_acc_std**2, self.initial_acc_std**2, self.initial_acc_std**2
            ])
            self.sqrt_covariance = np.linalg.cholesky(init_cov)

        self.current_time = times[-1]

        # Store initial state in history
        self.history.append(TrackState(
            time=self.current_time,
            state=self.state.copy(),
            covariance=self.sqrt_covariance.copy()
        ))

    def predict(self, dt: float):
        """
        Propagate state forward using CKF cubature propagation.
        """
        if self.state is None:
            raise ValueError("Filter not initialized")

        SQ = self._process_noise_sqrt(dt)

        # Use CKF propagation (cloned from RIPITT)
        self.state, self.sqrt_covariance = cubature_propagate(
            t0=self.current_time,
            x0=self.state,
            SP0=self.sqrt_covariance,
            t1=self.current_time + dt,
            f=self._dynamics_fn,
            SQ=SQ,
            rule=self.rule
        )

        self.current_time += dt

    def update(self, measurement: Dict[str, Any]):
        """
        Update state with a bearing measurement using CKF cubature update.
        """
        if self.state is None:
            raise ValueError("Filter not initialized")

        time = measurement['time_sec']
        sat_pos = measurement['satellite_pos_ecef']
        bearing_meas = measurement['bearing']
        meas_error = measurement.get('meas_error', self.r_angle)

        # Propagate to measurement time if needed
        if time > self.current_time:
            self.predict(time - self.current_time)

        # Measurement noise sqrt covariance
        SR = np.eye(3) * meas_error

        # Observation function for this measurement
        def h_obs(x):
            return self._observation_fn(x, sat_pos)

        # Use CKF update (cloned from RIPITT)
        self.state, self.sqrt_covariance, dz, Szz = cubature_update(
            x1p=self.state,
            SP1p=self.sqrt_covariance,
            z=bearing_meas,
            SR=SR,
            h=h_obs,
            rule=self.rule
        )

        # Store in history
        self.history.append(TrackState(
            time=time,
            state=self.state.copy(),
            covariance=self.sqrt_covariance.copy()
        ))

    def get_track_data(self) -> TrackData:
        """Convert history to TrackData format."""
        if not self.history:
            return TrackData(
                times=np.array([0.0]),
                x_states=np.zeros((1, 1, 9)),
                LT_covs=np.eye(9).reshape(1, 1, 9, 9)
            )

        times = np.array([s.time for s in self.history])
        states = np.array([s.state for s in self.history])
        covs = np.array([s.sqrt_covariance for s in self.history])

        return TrackData(
            times=times,
            x_states=states[np.newaxis, ...],
            LT_covs=covs[np.newaxis, ...]
        )


# =============================================================================
# Tracking Functions
# =============================================================================

def run_tracking_monte_carlo(
    measurements: List[Dict[str, Any]],
    truth_trajectory: np.ndarray,
    num_monte: int = 1,
    tracker_options: Dict[str, Any] = None,
    rng: np.random.Generator = None
) -> Tuple[TrackData, TrackMetrics]:
    """
    Run Monte Carlo tracking simulation.
    """
    if rng is None:
        rng = np.random.default_rng()

    if tracker_options is None:
        tracker_options = {
            'process_noise_accel': 10.0,
            'measurement_noise_angle': 5e-5,
            'num_measure_track_init': 5,
            'track_SNR_threshold': 1.0
        }

    # Convert measurements to filter input format
    filter_inputs = []
    for m in measurements:
        target_ecef = latlon_to_ecef(m['lat_deg'], m['lon_deg'], m['alt_km'] * 1000.0)
        sat_lat = m.get('sat_lat_deg', 0.0)
        sat_lon = m.get('sat_lon_deg', 0.0)
        sat_alt = m.get('sat_alt_km', 35786.0) * 1000.0
        sat_ecef = latlon_to_ecef(sat_lat, sat_lon, sat_alt)

        delta = target_ecef - sat_ecef
        bearing = delta / np.linalg.norm(delta)

        filter_inputs.append({
            'time_sec': m['time_sec'],
            'target_pos_ecef': target_ecef,
            'satellite_pos_ecef': sat_ecef,
            'bearing': bearing,
            'meas_error': m.get('meas_error', 5e-5)
        })

    filter_inputs.sort(key=lambda x: x['time_sec'])

    if len(filter_inputs) < 2:
        return _create_default_track_data(truth_trajectory)

    # Run Monte Carlo
    all_states = []
    all_covs = []
    all_times = None

    for mc_idx in range(num_monte):
        mc_rng = np.random.default_rng(rng.integers(0, 2**31) + mc_idx)

        filter_ = CWPAFilter(
            process_noise_accel=tracker_options.get('process_noise_accel', 10.0),
            measurement_noise_angle=tracker_options.get('measurement_noise_angle', 5e-5),
            rng=mc_rng
        )

        # Add measurement noise for this MC run
        noisy_inputs = []
        for inp in filter_inputs:
            noisy_inp = inp.copy()
            noise = mc_rng.standard_normal(3) * inp['meas_error']
            noisy_bearing = inp['bearing'] + noise
            noisy_bearing = noisy_bearing / np.linalg.norm(noisy_bearing)
            noisy_inp['bearing'] = noisy_bearing
            noisy_inputs.append(noisy_inp)

        # Initialize with first few measurements
        num_init = min(tracker_options.get('num_measure_track_init', 5), len(noisy_inputs))
        try:
            filter_.initialize(noisy_inputs[:num_init])
        except Exception:
            continue

        # Process remaining measurements
        for inp in noisy_inputs[num_init:]:
            try:
                filter_.update(inp)
            except Exception:
                continue

        # Extract track data
        if filter_.history:
            track_data = filter_.get_track_data()
            all_states.append(track_data.x_states[0])
            all_covs.append(track_data.LT_covs[0])
            if all_times is None:
                all_times = track_data.times

    if not all_states:
        return _create_default_track_data(truth_trajectory)

    times = all_times
    x_states = np.stack(all_states, axis=0)
    LT_covs = np.stack(all_covs, axis=0)

    track_data = TrackData(times=times, x_states=x_states, LT_covs=LT_covs)
    track_metrics = compute_track_metrics(track_data, truth_trajectory)

    return track_data, track_metrics


def compute_track_metrics(track_data: TrackData, truth_trajectory: np.ndarray) -> TrackMetrics:
    """Compute track errors vs ground truth."""
    times = track_data.times
    num_monte = track_data.num_monte
    num_times = track_data.num_time_points

    pos_errors = np.zeros((num_monte, num_times, 3))
    vel_errors = np.zeros((num_monte, num_times, 3))
    acc_errors = np.zeros((num_monte, num_times, 3))

    truth_times = truth_trajectory[:, 0]

    for t_idx, t in enumerate(times):
        idx = np.argmin(np.abs(truth_times - t))

        true_lat = truth_trajectory[idx, 1]
        true_lon = truth_trajectory[idx, 2]
        true_alt = truth_trajectory[idx, 3]
        true_pos = latlon_to_ecef(true_lat, true_lon, true_alt)

        if idx > 0 and idx < len(truth_trajectory) - 1:
            dt = truth_trajectory[idx + 1, 0] - truth_trajectory[idx - 1, 0]
            if dt > 0:
                pos_prev = latlon_to_ecef(
                    truth_trajectory[idx - 1, 1],
                    truth_trajectory[idx - 1, 2],
                    truth_trajectory[idx - 1, 3]
                )
                pos_next = latlon_to_ecef(
                    truth_trajectory[idx + 1, 1],
                    truth_trajectory[idx + 1, 2],
                    truth_trajectory[idx + 1, 3]
                )
                true_vel = (pos_next - pos_prev) / dt
            else:
                true_vel = np.zeros(3)
        else:
            true_vel = np.zeros(3)

        true_acc = np.zeros(3)

        for mc_idx in range(num_monte):
            est_pos = track_data.positions_ecef[mc_idx, t_idx]
            est_vel = track_data.velocities_ecef[mc_idx, t_idx]
            est_acc = track_data.accelerations_ecef[mc_idx, t_idx]

            pos_errors[mc_idx, t_idx] = est_pos - true_pos
            vel_errors[mc_idx, t_idx] = est_vel - true_vel
            acc_errors[mc_idx, t_idx] = est_acc - true_acc

    return TrackMetrics(
        track_times=times,
        pos_errors_m=pos_errors,
        vel_errors_mps=vel_errors,
        acc_errors_mps2=acc_errors,
        LT_covs=track_data.LT_covs
    )


def _create_default_track_data(truth_trajectory: np.ndarray) -> Tuple[TrackData, TrackMetrics]:
    """Create default track data from truth trajectory when tracking fails."""
    times = truth_trajectory[:, 0]
    num_times = len(times)

    states = np.zeros((1, num_times, 9))
    covs = np.zeros((1, num_times, 9, 9))

    prev_pos = None
    prev_vel = None

    for i, row in enumerate(truth_trajectory):
        pos = latlon_to_ecef(row[1], row[2], row[3])

        if prev_pos is not None and i > 0:
            dt = times[i] - times[i-1]
            if dt > 0:
                vel = (pos - prev_pos) / dt
            else:
                vel = np.zeros(3)
        else:
            vel = np.zeros(3)

        if prev_vel is not None and i > 0:
            dt = times[i] - times[i-1]
            if dt > 0:
                acc = (vel - prev_vel) / dt
            else:
                acc = np.zeros(3)
        else:
            acc = np.zeros(3)

        states[0, i, :3] = pos
        states[0, i, 3:6] = vel
        states[0, i, 6:9] = acc

        default_cov = np.diag([
            10000.0**2, 10000.0**2, 10000.0**2,
            1000.0**2, 1000.0**2, 1000.0**2,
            100.0**2, 100.0**2, 100.0**2
        ])
        covs[0, i] = np.linalg.cholesky(default_cov)

        prev_pos = pos
        prev_vel = vel

    track_data = TrackData(times=times, x_states=states, LT_covs=covs)

    track_metrics = TrackMetrics(
        track_times=times,
        pos_errors_m=np.zeros((1, num_times, 3)),
        vel_errors_mps=np.zeros((1, num_times, 3)),
        acc_errors_mps2=np.zeros((1, num_times, 3)),
        LT_covs=covs
    )

    return track_data, track_metrics


def run_tracking(detections: List[Dict[str, Any]],
                  satellites: List[Dict[str, Any]] = None) -> TrackData:
    """
    Run tracking on HOSS detections to produce track data with covariance.
    """
    if not detections:
        return TrackData(
            times=np.array([0.0]),
            x_states=np.zeros((1, 1, 9)),
            LT_covs=np.eye(9).reshape(1, 1, 9, 9) * 10000
        )

    if satellites is None:
        satellites = []

    sat_lookup = {sat['id']: sat for sat in satellites}

    filter_inputs = []
    for det in detections:
        target_ecef = latlon_to_ecef(det['lat_deg'], det['lon_deg'], det['alt_km'] * 1000.0)

        sat_id = det.get('satellite_id', 'GEO-1')
        if sat_id in sat_lookup:
            sat = sat_lookup[sat_id]
            sat_lat = sat.get('lat_deg', 0.0)
            sat_lon = sat.get('lon_deg', 0.0)
            sat_alt = sat.get('altitude_km', 35786.0) * 1000.0
        else:
            sat_lat = 0.0
            sat_lon = det.get('lon_deg', 0.0)
            sat_alt = 35786.0 * 1000.0

        sat_ecef = latlon_to_ecef(sat_lat, sat_lon, sat_alt)

        delta = target_ecef - sat_ecef
        range_m = np.linalg.norm(delta)
        if range_m < 1.0:
            continue
        bearing = delta / range_m

        filter_inputs.append({
            'time_sec': det['time_sec'],
            'target_pos_ecef': target_ecef,
            'satellite_pos_ecef': sat_ecef,
            'bearing': bearing,
            'meas_error': 5e-5
        })

    filter_inputs.sort(key=lambda x: x['time_sec'])

    if len(filter_inputs) < 2:
        if filter_inputs:
            t = filter_inputs[0]['time_sec']
            pos = filter_inputs[0]['target_pos_ecef']
            state = np.concatenate([pos, np.zeros(6)])
            return TrackData(
                times=np.array([t]),
                x_states=state.reshape(1, 1, 9),
                LT_covs=np.eye(9).reshape(1, 1, 9, 9) * 10000
            )
        return TrackData(
            times=np.array([0.0]),
            x_states=np.zeros((1, 1, 9)),
            LT_covs=np.eye(9).reshape(1, 1, 9, 9) * 10000
        )

    # Create and run CKF filter (cloned from RIPITT)
    tracker = CWPAFilter(
        process_noise_accel=10.0,
        measurement_noise_angle=5e-5
    )

    num_init = min(5, len(filter_inputs))
    try:
        tracker.initialize(filter_inputs[:num_init])
    except Exception:
        return TrackData(
            times=np.array([filter_inputs[0]['time_sec']]),
            x_states=np.zeros((1, 1, 9)),
            LT_covs=np.eye(9).reshape(1, 1, 9, 9) * 10000
        )

    for inp in filter_inputs[num_init:]:
        try:
            tracker.update(inp)
        except Exception:
            continue

    if tracker.history:
        return tracker.get_track_data()

    return TrackData(
        times=np.array([0.0]),
        x_states=np.zeros((1, 1, 9)),
        LT_covs=np.eye(9).reshape(1, 1, 9, 9) * 10000
    )


__all__ = [
    'TrackState',
    'TrackData',
    'TrackMetrics',
    'CWPAFilter',
    'run_tracking',
    'run_tracking_monte_carlo',
    'compute_track_metrics',
    'latlon_to_ecef',
    # CKF exports (cloned from RIPITT)
    'Stroud53Rule',
    'cubature_propagate',
    'cubature_update',
    'sqrt_transform_qr',
    'nonlinear_least_squares'
]
